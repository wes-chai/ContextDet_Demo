{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538a235d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade requests_mock clyent==1.2.1 PyYAML==6.0.1 tensorboard tensorflow-estimator==2.14.0 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6dff032",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e9c4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position interpolate from 16x16 to 26x26\n"
     ]
    }
   ],
   "source": [
    "from app import inference_fn_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae05d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('main_1.jpg')\n",
    "inference_fn_select(img, '', 'Captioning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927bce45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img2 = Image.open('coke.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e171f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_fn_select(img2, '', 'Captioning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7808ef92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img3 = Image.open('four_construction_workers.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a510a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_fn_select(img3, 'Are these construction workers wearing hard hats?', 'Question Answering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b803b06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img4 = Image.open('plants.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f3e1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_fn_select(img4, 'Do these leaves have holes in them?', 'Question Answering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43fc5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img5 = Image.open('flotsam.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc45498",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_fn_select(img5, 'Does this pond have flotsam or buoys?', 'Question Answering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7f7b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img6 = Image.open('forestfire.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d401c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_fn_select(img6, 'Is this forest burning?', 'Question Answering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac40870",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img7 = Image.open('001-crossed.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8ee051",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_fn_select(img7, 'Is this construction worker wearing a hard hat and long boots?', 'Question Answering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7577369",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "imgw = Image.open('jobframes/1.png')\n",
    "\n",
    "inference_fn_select(imgw, '', 'Captioning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa19f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgw = Image.open('jobframes/2.png')\n",
    "\n",
    "inference_fn_select(imgw, '', 'Captioning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0e1073",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgw = Image.open('jobframes/3.png')\n",
    "\n",
    "inference_fn_select(imgw, '', 'Captioning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858397df",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgw = Image.open('jobframes/4.png')\n",
    "\n",
    "inference_fn_select(imgw, '', 'Captioning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f42f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgw = Image.open('jobframes/5.png')\n",
    "\n",
    "inference_fn_select(imgw, '', 'Captioning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c30eb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgw = Image.open('jobframes/6.png')\n",
    "\n",
    "inference_fn_select(imgw, '', 'Captioning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25034bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgw = Image.open('jobframes/7.png')\n",
    "\n",
    "inference_fn_select(imgw, '', 'Captioning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a201ac44",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgw = Image.open('jobframes/v01-p01.jpg')\n",
    "\n",
    "inference_fn_select(imgw, '', 'Captioning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0559bada",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgw = Image.open('jobframes/v01-p02.jpg')\n",
    "\n",
    "inference_fn_select(imgw, '', 'Captioning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2379337",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgw = Image.open('jobframes/v01-p03.jpg')\n",
    "\n",
    "inference_fn_select(imgw, '', 'Captioning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7d3079",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgw = Image.open('jobframes/v01-p04.jpg')\n",
    "\n",
    "inference_fn_select(imgw, '', 'Captioning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa904f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgw = Image.open('jobframes/v01-p05.jpg')\n",
    "\n",
    "inference_fn_select(imgw, '', 'Captioning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd07e236",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgw = Image.open('jobframes/v01-p06.jpg')\n",
    "\n",
    "inference_fn_select(imgw, '', 'Captioning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12005984",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgw = Image.open('jobframes/v01-p07.jpg')\n",
    "\n",
    "inference_fn_select(imgw, '', 'Captioning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d8902c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "vidcap = cv2.VideoCapture('pantry/tm005.mp4')\n",
    "count = 0\n",
    "success = True\n",
    "fps = int(vidcap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "while success:\n",
    "    success, image = vidcap.read()\n",
    "    print('Read a new frame:', success)\n",
    "    if count%(10*fps) == 0 :\n",
    "         cv2.imwrite('jobframes/frame%d.jpg'%count,image)\n",
    "         print('successfully written 10th frame')\n",
    "    count+=1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
